{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw01.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Causality and Expressions\n",
    "\n",
    "Please complete this notebook by filling in the cells provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recommended Reading:**\n",
    "- [What is Data Science](http://www.inferentialthinking.com/chapters/01/what-is-data-science.html)\n",
    "- [Causality and Experiments](http://www.inferentialthinking.com/chapters/02/causality-and-experiments.html) \n",
    "- [Programming in Python](http://www.inferentialthinking.com/chapters/03/programming-in-python.html)\n",
    "\n",
    "For all problems that you must write explanations and sentences for, you **must** provide your answer in the designated space. Moreover, throughout this homework and all future ones, please be sure to not re-assign variables throughout the notebook! For example, if you use `max_temperature` in your answer to one question, do not reassign it later on. Otherwise, you will fail tests that you thought you were passing previously!\n",
    "\n",
    "\n",
    "Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged. Refer to the policies page to learn more about how to learn cooperatively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scary Arithmetic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "An ad for ADT Security Systems says,\n",
    "\n",
    "> \"When you go on vacation, burglars go to work [...] According to FBI statistics, over 25% of home burglaries occur between Memorial Day and Labor Day.\"\n",
    "\n",
    "Do the data in the ad support the claim that burglars are more likely to go to work during the time between Memorial Day and Labor Day? Please explain your answer.\n",
    "\n",
    "**Note:** You can assume that \"over 25%\" means only slightly over. Had it been much over, say closer to 30%, then the marketers would have said so.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## 2. Characters in Little Women\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lecture, we counted the number of times that the literary characters were named in each chapter of the classic book, [*Little Women*](https://www.inferentialthinking.com/chapters/01/3/1/literary-characters). In computer science, the word \"character\" also refers to a letter, digit, space, or punctuation mark; any single element of a text. The following code generates a scatter plot in which each dot corresponds to a chapter of *Little Women*. The horizontal position of a dot measures the number of periods in the chapter. The vertical position measures the total number of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This cell contains code that hasn't yet been covered in the course,\n",
    "# but you should be able to interpret the scatter plot it generates.\n",
    "\n",
    "from datascience import *\n",
    "from urllib.request import urlopen\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "little_women_url = 'https://www.inferentialthinking.com/data/little_women.txt'\n",
    "chapters = urlopen(little_women_url).read().decode().split('CHAPTER ')[1:]\n",
    "text = Table().with_column('Chapters', chapters)\n",
    "Table().with_columns(\n",
    "    'Periods',    np.char.count(chapters, '.'),\n",
    "    'Characters', text.apply(len, 0)\n",
    "    ).scatter(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1.** Around how many periods are there in the chapter with the most characters? Assign either 1, 2, 3, 4, or 5 to the name `characters_q1` below.\n",
    "\n",
    "1. 250\n",
    "2. 390\n",
    "3. 440\n",
    "4. 32,000\n",
    "5. 40,000\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_1\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_q1 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <p><strong>q2_1</strong> passed!</p>\n",
       "    "
      ],
      "text/plain": [
       "q2_1 passed!"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test above checks that your answers are in the correct format. **This test does not check that you answered correctly**, only that you assigned a number successfully in each multiple-choice answer cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.** Which of the following chapters has the most characters per period? Assign either 1, 2, or 3 to the name `characters_q2` below.\n",
    "1. The chapter with about 60 periods\n",
    "2. The chapter with about 350 periods\n",
    "3. The chapter with about 440 periods\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_2\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_q2 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <p><strong>q2_2</strong> passed!</p>\n",
       "    "
      ],
      "text/plain": [
       "q2_2 passed!"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the test above checks that your answers are in the correct format, but not that you have answered correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To discover more interesting facts from this plot, read [Section 1.3.2](https://www.inferentialthinking.com/chapters/01/3/2/another-kind-of-character) of the textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Names and Assignment Statements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** When you run the following cell, Python produces a cryptic error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to literal (<ipython-input-9-4c8b769209ad>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-4c8b769209ad>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    4 = 2 + 2\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to literal\n"
     ]
    }
   ],
   "source": [
    "4 = 2 + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Choose the best explanation of what's wrong with the code, and then assign 1, 2, 3, or 4 to `names_q1` below to indicate your answer.\n",
    "\n",
    "1. Python is smart and already knows `4 = 2 + 2`.\n",
    "\n",
    "2. `4` is already a defined number, and it doesn't make sense to make a number be a name for something else. In Python, \"`x = 2 + 2`\" means \"assign `x` as the name for the value of `2 + 2`.\"\n",
    "\n",
    "3. It should be `2 + 2 = 4`.\n",
    "\n",
    "4. I don't get an error message. This is a trick question.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_1\n",
    "manual: False\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_q1 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <p><strong>q3_1</strong> passed!</p>\n",
       "    "
      ],
      "text/plain": [
       "q3_1 passed!"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** When you run the following cell, Python will produce another cryptic error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-820d4d61e3dd>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-820d4d61e3dd>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    six = two plus two\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "two = 3\n",
    "six = two plus two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Choose the best explanation of what's wrong with the code and assign 1, 2, 3, or 4 to `names_q2` below to indicate your answer.\n",
    "\n",
    "1. The `plus` operation only applies to numbers, not the word \"two\".\n",
    "\n",
    "2. The name \"two\" cannot be assigned to the number 3.\n",
    "\n",
    "3. Two plus two is four, not six.\n",
    "\n",
    "4. Python cannot interpret the name `two` followed directly by a name that has not been defined.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_2\n",
    "manual: False\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_q2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <p><strong style='color: red;'>q3_2</strong></p>\n",
       "    <p><strong>Test result:</strong></p>\n",
       "    \n",
       "        <p><em>q3_2 - 1</em>\n",
       "        \n",
       "            <pre>Trying:\n",
       "    1 <= names_q2 <= 4\n",
       "Expecting:\n",
       "    True\n",
       "**********************************************************************\n",
       "Line 1, in q3_2 0\n",
       "Failed example:\n",
       "    1 <= names_q2 <= 4\n",
       "Exception raised:\n",
       "    Traceback (most recent call last):\n",
       "      File \"/opt/conda/lib/python3.7/doctest.py\", line 1337, in __run\n",
       "        compileflags, 1), test.globs)\n",
       "      File \"<doctest q3_2 0[0]>\", line 1, in <module>\n",
       "        1 <= names_q2 <= 4\n",
       "    TypeError: '<=' not supported between instances of 'int' and 'ellipsis'\n",
       "</pre>\n",
       "        \n",
       "        </p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "q3_2 results:\n",
       "\n",
       "Trying:\n",
       "    1 <= names_q2 <= 4\n",
       "Expecting:\n",
       "    True\n",
       "**********************************************************************\n",
       "Line 1, in q3_2 0\n",
       "Failed example:\n",
       "    1 <= names_q2 <= 4\n",
       "Exception raised:\n",
       "    Traceback (most recent call last):\n",
       "      File \"/opt/conda/lib/python3.7/doctest.py\", line 1337, in __run\n",
       "        compileflags, 1), test.globs)\n",
       "      File \"<doctest q3_2 0[0]>\", line 1, in <module>\n",
       "        1 <= names_q2 <= 4\n",
       "    TypeError: '<=' not supported between instances of 'int' and 'ellipsis'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** When you run the following cell, Python will, yet again, produce another cryptic error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-94f783b16b3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "x = print(5)\n",
    "y = x + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Choose the best explanation of what's wrong with the code and assign 1, 2, or 3 to `names_q3` below to indicate your answer.\n",
    "\n",
    "1. Python doesn't want `y` to be assigned.\n",
    "\n",
    "2. The `print` operation is meant for displaying values to the programmer, not for assigning values!\n",
    "\n",
    "3. Python can’t do addition between one name and one number. It has to be 2 numbers or 2 predefined names.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_3\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_q3 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <p><strong style='color: red;'>q3_3</strong></p>\n",
       "    <p><strong>Test result:</strong></p>\n",
       "    \n",
       "        <p><em>q3_3 - 1</em>\n",
       "        \n",
       "            <pre>Trying:\n",
       "    1 <= names_q3 <= 4\n",
       "Expecting:\n",
       "    True\n",
       "**********************************************************************\n",
       "Line 1, in q3_3 0\n",
       "Failed example:\n",
       "    1 <= names_q3 <= 4\n",
       "Exception raised:\n",
       "    Traceback (most recent call last):\n",
       "      File \"/opt/conda/lib/python3.7/doctest.py\", line 1337, in __run\n",
       "        compileflags, 1), test.globs)\n",
       "      File \"<doctest q3_3 0[0]>\", line 1, in <module>\n",
       "        1 <= names_q3 <= 4\n",
       "    TypeError: '<=' not supported between instances of 'int' and 'ellipsis'\n",
       "</pre>\n",
       "        \n",
       "        </p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "q3_3 results:\n",
       "\n",
       "Trying:\n",
       "    1 <= names_q3 <= 4\n",
       "Expecting:\n",
       "    True\n",
       "**********************************************************************\n",
       "Line 1, in q3_3 0\n",
       "Failed example:\n",
       "    1 <= names_q3 <= 4\n",
       "Exception raised:\n",
       "    Traceback (most recent call last):\n",
       "      File \"/opt/conda/lib/python3.7/doctest.py\", line 1337, in __run\n",
       "        compileflags, 1), test.globs)\n",
       "      File \"<doctest q3_3 0[0]>\", line 1, in <module>\n",
       "        1 <= names_q3 <= 4\n",
       "    TypeError: '<=' not supported between instances of 'int' and 'ellipsis'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Job Opportunities & Education in Rural India\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [study](http://www.nber.org/papers/w16021.pdf) at UCLA investigated factors that might result in greater attention to the health and education of girls in rural India. One such factor is information about job opportunities for women. The idea is that if people know that educated women can get good jobs, they might take more care of the health and education of girls in their families, as an investment in the girls’ future potential as earners. Without the knowledge of job opportunities, the author hypothesizes that families do not invest in women’s well-being.\n",
    "\n",
    "The study focused on 160 villages outside the capital of India, all with little access to information about call centers and similar organizations that offer job opportunities to women. In 80 of the villages chosen at random, recruiters visited the village, described the opportunities, recruited women who had some English language proficiency and experience with computers, and provided ongoing support free of charge for three years. In the other 80 villages, no recruiters visited and no other intervention was made.\n",
    "\n",
    "At the end of the study period, the researchers recorded data about the school attendance and health of the children in the villages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1.** Which statement best describes the *treatment* and *control* groups for this study? Assign either 1, 2, or 3 to the name `jobs_q1` below.\n",
    "\n",
    "1. The treatment group was the 80 villages visited by recruiters, and the control group was the other 80 villages with no intervention.\n",
    "\n",
    "2. The treatment group was the 160 villages selected, and the control group was the rest of the villages outside the capital of India.\n",
    "\n",
    "3. There is no clear notion of *treatment* and *control* group in this study.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4_1\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_q1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <p><strong style='color: red;'>q4_1</strong></p>\n",
       "    <p><strong>Test result:</strong></p>\n",
       "    \n",
       "        <p><em>q4_1 - 1</em>\n",
       "        \n",
       "            <pre>Trying:\n",
       "    1 <= jobs_q1 <= 3\n",
       "Expecting:\n",
       "    True\n",
       "**********************************************************************\n",
       "Line 1, in q4_1 0\n",
       "Failed example:\n",
       "    1 <= jobs_q1 <= 3\n",
       "Exception raised:\n",
       "    Traceback (most recent call last):\n",
       "      File \"/opt/conda/lib/python3.7/doctest.py\", line 1337, in __run\n",
       "        compileflags, 1), test.globs)\n",
       "      File \"<doctest q4_1 0[0]>\", line 1, in <module>\n",
       "        1 <= jobs_q1 <= 3\n",
       "    TypeError: '<=' not supported between instances of 'int' and 'ellipsis'\n",
       "</pre>\n",
       "        \n",
       "        </p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "q4_1 results:\n",
       "\n",
       "Trying:\n",
       "    1 <= jobs_q1 <= 3\n",
       "Expecting:\n",
       "    True\n",
       "**********************************************************************\n",
       "Line 1, in q4_1 0\n",
       "Failed example:\n",
       "    1 <= jobs_q1 <= 3\n",
       "Exception raised:\n",
       "    Traceback (most recent call last):\n",
       "      File \"/opt/conda/lib/python3.7/doctest.py\", line 1337, in __run\n",
       "        compileflags, 1), test.globs)\n",
       "      File \"<doctest q4_1 0[0]>\", line 1, in <module>\n",
       "        1 <= jobs_q1 <= 3\n",
       "    TypeError: '<=' not supported between instances of 'int' and 'ellipsis'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.** Was this an observational study or a randomized controlled experiment? Assign either 1, 2, or 3 to the name `jobs_q2` below.\n",
    "\n",
    "1. This was an observational study.\n",
    "\n",
    "2. This was a randomized controlled experiment.  \n",
    "\n",
    "3. This was a randomized observational study.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4_2\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_q2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <p><strong style='color: red;'>q4_2</strong></p>\n",
       "    <p><strong>Test result:</strong></p>\n",
       "    \n",
       "        <p><em>q4_2 - 1</em>\n",
       "        \n",
       "            <pre>Trying:\n",
       "    1 <= jobs_q2 <= 3\n",
       "Expecting:\n",
       "    True\n",
       "**********************************************************************\n",
       "Line 1, in q4_2 0\n",
       "Failed example:\n",
       "    1 <= jobs_q2 <= 3\n",
       "Exception raised:\n",
       "    Traceback (most recent call last):\n",
       "      File \"/opt/conda/lib/python3.7/doctest.py\", line 1337, in __run\n",
       "        compileflags, 1), test.globs)\n",
       "      File \"<doctest q4_2 0[0]>\", line 1, in <module>\n",
       "        1 <= jobs_q2 <= 3\n",
       "    TypeError: '<=' not supported between instances of 'int' and 'ellipsis'\n",
       "</pre>\n",
       "        \n",
       "        </p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "q4_2 results:\n",
       "\n",
       "Trying:\n",
       "    1 <= jobs_q2 <= 3\n",
       "Expecting:\n",
       "    True\n",
       "**********************************************************************\n",
       "Line 1, in q4_2 0\n",
       "Failed example:\n",
       "    1 <= jobs_q2 <= 3\n",
       "Exception raised:\n",
       "    Traceback (most recent call last):\n",
       "      File \"/opt/conda/lib/python3.7/doctest.py\", line 1337, in __run\n",
       "        compileflags, 1), test.globs)\n",
       "      File \"<doctest q4_2 0[0]>\", line 1, in <module>\n",
       "        1 <= jobs_q2 <= 3\n",
       "    TypeError: '<=' not supported between instances of 'int' and 'ellipsis'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 3.** The study reported, \"Girls aged 5-15 in villages that received the recruiting services were 3 to 5 percentage points more likely to be in school and experienced an increase in Body Mass Index, reflecting greater nutrition and/or medical care. However, there was no net gain in height. For boys, there was no change in any of these measures.\" Why do you think the author points out the lack of change in the boys?\n",
    "\n",
    "*Hint:* Remember the original hypothesis. The author believes that educating women in job opportunities will cause families to invest more in the women’s well-being.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4_3\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## 5. Differences between Majors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berkeley’s Office of Planning and Analysis provides data on numerous aspects of the campus. Adapted from the OPA website, the table below displays the numbers of degree recipients in three majors in the academic years 2008-2009 and 2017-2018.\n",
    "\n",
    "| Major                              | 2008-2009    | 2017-2018   |\n",
    "|------------------------------------|--------------|-------------|\n",
    "| Gender and Women's Studies         |      17      |    28       |\n",
    "| Linguistics                        |      49      |    67       |\n",
    "| Rhetoric                           |      113     |    56       |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.** Suppose you want to find the **biggest** absolute difference between the numbers of degree recipients in the two years, among the three majors.\n",
    "\n",
    "In the cell below, compute this value and call it `biggest_change`. Use a single expression (a single line of code) to compute the answer. Let Python perform all the arithmetic (like subtracting 49 from 67) rather than simplifying the expression yourself. The built-in `abs` function takes a numerical input and returns the absolute value. The built-in `max` function can take in 3 arguments and returns the maximum of the three numbers\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5_1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "export_pdf": true
   },
   "outputs": [],
   "source": [
    "biggest_change = ...\n",
    "biggest_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 2.** Which of the three majors had the **smallest** absolute difference? Assign `smallest_change_major` to 1, 2, or 3 where each number corresponds to the following major:\n",
    "\n",
    "1: Gender and Women's Studies  \n",
    "2: Linguistics  \n",
    "3: Rhetoric\n",
    "\n",
    "Choose the number that corresponds to the major with the smallest absolute difference.\n",
    "\n",
    "You should be able to answer by rough mental arithmetic, without having to calculate the exact value for each major. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5_2\n",
    "manual: False\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_change_major = ...\n",
    "smallest_change_major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 3.**  For each major, define the \"relative change\" to be the following: $\\large{\\frac{\\text{absolute difference}}{\\text{value in 2008-2009}} * 100}$ \n",
    "\n",
    "Fill in the code below such that `gws_relative_change`, `linguistics_relative_change` and `rhetoric_relative_change` are assigned to the relative changes for their respective majors.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5_3\n",
    "manual: False\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "gws_relative_change = (abs(...) / 17) * 100\n",
    "linguistics_relative_change = ...\n",
    "rhetoric_relative_change = ...\n",
    "gws_relative_change, linguistics_relative_change, rhetoric_relative_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 4.** Assign `biggest_rel_change_major` to 1, 2, or 3 where each number corresponds to to the following: \n",
    "\n",
    "1: Gender and Women's Studies  \n",
    "2: Linguistics  \n",
    "3: Rhetoric\n",
    "\n",
    "Choose the number that corresponds to the major with the biggest relative change.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5_4\n",
    "manual: False\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign biggest_rel_change_major to the number corresponding to the major with the biggest relative change.\n",
    "biggest_rel_change_major = ...\n",
    "biggest_rel_change_major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Nearsightedness Study\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Myopia, or nearsightedness, results from a number of genetic and environmental factors. In 1999, Quinn et al studied the relation between myopia and ambient lighting at night (for example, from nightlights or room lights) during childhood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.** The data were gathered by the following procedure, reported in the study. \"Between January and June 1998, parents of children aged 2-16 years [...] that were seen as outpatients in a university pediatric ophthalmology clinic completed a questionnaire on the child’s light exposure both at present and before the age of 2 years.\" Was this study observational, or was it a controlled experiment? Explain. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6_1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2.** The study found that of the children who slept with a room light on before the age of 2, 55% were myopic. Of the children who slept with a night light on before the age of 2, 34% were myopic. Of the children who slept in the dark before the age of 2, 10% were myopic. The study concluded that, \"The prevalence of myopia [...] during childhood was strongly associated with ambient light exposure during sleep at night in the first two years after birth.\"\n",
    "\n",
    "Do the data support this statement? You may interpret \"strongly\" in any reasonable qualitative way.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6_2\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 3.** On May 13, 1999, CNN reported the results of this study under the headline, \"Night light may lead to nearsightedness.\" Does the conclusion of the study claim that night light causes nearsightedness?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6_3\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 4.** The final paragraph of the CNN report said that \"several eye specialists\" had pointed out that the study should have accounted for heredity.\n",
    "\n",
    "Myopia is passed down from parents to children. Myopic parents are more likely to have myopic children, and may also be more likely to leave lights on habitually (since the parents have poor vision). In what way does the knowledge of this possible genetic link affect how we interpret the data from the study? \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6_4\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## 7. Studying the Survivors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The Reverend Henry Whitehead was skeptical of John Snow’s conclusion about the Broad Street pump. After the Broad Street cholera epidemic ended, Whitehead set about trying to prove Snow wrong.  (The history of the event is detailed [here](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1034367/pdf/medhist00183-0026.pdf).)\n",
    "\n",
    "He realized that Snow had focused his analysis almost entirely on those who had died. Whitehead, therefore, investigated the drinking habits of people in the Broad Street area who had not died in the outbreak.\n",
    "\n",
    "What is the main reason it was important to study this group?\n",
    "\n",
    "1) If Whitehead had found that many people had drunk water from the Broad Street pump and not caught cholera, that would have been evidence against Snow's hypothesis.\n",
    "\n",
    "2) Survivors could provide additional information about what else could have caused the cholera, potentially unearthing another cause.\n",
    "\n",
    "3) Through considering the survivors, Whitehead could have identified a cure for cholera.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7_1\n",
    "manual: False\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign survivor_answer to 1, 2, or 3\n",
    "survivor_answer = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Whitehead ended up finding further proof that the Broad Street pump played the central role in spreading the disease to the people who lived near it. Eventually, he became one of Snow’s greatest defenders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Policies and Administrivia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the homework is to ensure that you have read over the policies and frequently asked questions for the course. \n",
    "\n",
    "**It's important that you read through this section of the homework very carefully**. If you can get through all of this section and are sure you have all of the correct resources set up, you will be able to focus on the actual material this semester!\n",
    "\n",
    "Reading through the [policies](http://data8.org/sp20/policies.html) and the [FAQ](http://data8.org/sp20/faq.html) will help you get through this section very easily. It is recommended you do this before. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1:** You have a question regarding the grading of your assignments that has not been previously answered on Piazza or the FAQ. Who do you contact? Assign `contact` to the number corresponding to the best choice below. \n",
    "\n",
    "1. The Instructors\n",
    "2. Post on Piazza\n",
    "3. Contact your Lab TA\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8_1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2:** Why will the grades on Gradescope and OkPy be different? Assign `grades` to the number corresponding to the best choice below. \n",
    "\n",
    "1. There was a mistake in the grading. I should contact someone about this\n",
    "2. Gradescope grades the written portion, while OkPy grades the coded portion\n",
    "3. Trick question; the grades should be the same on both platforms\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8_2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 3:** Regrade deadline dates will always be posted on the same Piazza post that releases the assignment grades, common mistakes, and solutions. Can you ask for parts of your assignment regraded after the regrade request window has passed? Assign `regrade` to the number corresponding to the best choice below. \n",
    "\n",
    "1. Yes\n",
    "2. No\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8_3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regrade = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q8_3</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q8_3 results: All test cases passed!"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q8_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 4:** Do you have an Gradescope account? Head to [gradescope.com](http://gradescope.com) and check if you see Data 8. If you do not, please send your Lab TA an email with your email and student ID number. \n",
    "\n",
    "Once you have been enrolled, go to the Data 8 Gradescope course website. At the end of the url (link), you should see a number. Assign `gradescope` to that number. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8_4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradescope = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 5:** Given the following scenarios, assign `acceptable` to the number of the scenario that is permissible given the guidelines on the [policies](http://data8.org/sp20/policies.html) page. \n",
    "\n",
    "1. Alice gets stuck on a homework assignment, so she googles a fix. She stumbles across a pdf of the solutions for the homework assignment from a previous semester's offering of Data 8. After inspecting the solution, Alice writes her own solution and submits the assignment.\n",
    "\n",
    "2. After getting confused by a project, Bob asks his friend for help. His friend helps by walking the student through his own logic, pointing out areas that are important given the context of the question. Upon hearing his friends logic, the Bob writes his own code and completes the project.\n",
    "\n",
    "3. Eve has an extremely busy schedule, so she really wants to leave lab early by finishing it and getting checked off. Her neighbor, Charlie, simply turns his computer so Eve can see how he completed some questions. After looking at his code, Eve finishes the lab and gets checked off.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8_5\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptable = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 6:** To make sure you have read through the [policies](http://data8.org/sp20/policies.html) and the [FAQ](http://data8.org/sp20/faq.html) carefully, how many HW/lab drops are there? Assign `drops` to the number corresponding to the best choice below. \n",
    "\n",
    "1. Two homework drops and one lab drop\n",
    "2. One homework drop and one lab drop\n",
    "3. Only one homework drop\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8_6\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 7:** Does Data 8 offer any alternate exams? Assign `exams` to the number corresponding to the best choice below. \n",
    "\n",
    "1. Yes\n",
    "2. No\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8_7\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 8:** Are you actually checking Piazza? Go to this semester's [Data 8 Piazza](https://piazza.com/class/k5fwiw4wql642x), and find an instructor posted thread with a certain secret phrase. Assign `secret` to this secret phrase in quotes (aka as a string).\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8_8\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Welcome Survey\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have submitted, please also complete the welcome survey in order to receive credit for homework 1.\n",
    "\n",
    "Welcome survey is here: https://docs.google.com/forms/d/e/1FAIpQLSd28-DvELnGk4n6lHcqMOWcsovDulNSbhmlLFXqDMQIsdldaQ/viewform?usp=sf_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Assign `survey` to the secret string given at the end of the welcome survey:\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q9\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <p>Your submission has been exported. Click <a href=\"hw01.zip\" target=\"_blank\">here</a>\n",
       "                to download the zip file.</p>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "section": "1",
  "course": "8x",
  "lab": "lab01",
  "celltoolbar": "None",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
